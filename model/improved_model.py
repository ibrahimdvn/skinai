import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.applications import EfficientNetB3
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import (
    Dense, Dropout, GlobalAveragePooling2D, 
    BatchNormalization, Conv2D, MaxPooling2D
)
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import (
    EarlyStopping, ModelCheckpoint, ReduceLROnPlateau,
    CosineAnnealingScheduler, LearningRateScheduler
)
from tensorflow.keras.metrics import Precision, Recall, AUC
import matplotlib.pyplot as plt
from pathlib import Path
import json
from sklearn.utils.class_weight import compute_class_weight

# Reproducibility i√ßin seed ayarla
tf.random.set_seed(42)
np.random.seed(42)

class ImprovedSkinCancerCNN:
    def __init__(self):
        self.model = None
        self.history = None
        self.class_names = ['benign', 'melanoma', 'nevus']
        self.img_size = (224, 224)
        self.batch_size = 16  # Daha k√º√ß√ºk batch size
        
    def create_transfer_learning_model(self):
        """Transfer learning ile geli≈ümi≈ü model olu≈üturur."""
        print("üß† Transfer Learning ile geli≈ümi≈ü CNN modeli olu≈üturuluyor...")
        
        # Pre-trained EfficientNetB3 base model
        base_model = EfficientNetB3(
            weights='imagenet',
            include_top=False,
            input_shape=(224, 224, 3)
        )
        
        # ƒ∞lk katmanlarƒ± dondur
        base_model.trainable = False
        
        # Model mimarisi
        model = Sequential([
            base_model,
            GlobalAveragePooling2D(),
            BatchNormalization(),
            Dense(512, activation='relu'),
            Dropout(0.5),
            BatchNormalization(),
            Dense(256, activation='relu'),
            Dropout(0.3),
            BatchNormalization(),
            Dense(128, activation='relu'),
            Dropout(0.2),
            Dense(3, activation='softmax')  # 3 sƒ±nƒ±f
        ])
        
        # ƒ∞lk eƒüitim - frozen base
        model.compile(
            optimizer=Adam(learning_rate=0.001),
            loss='categorical_crossentropy',
            metrics=['accuracy', Precision(), Recall(), AUC()]
        )
        
        self.model = model
        print("‚úÖ Transfer learning modeli olu≈üturuldu!")
        print(f"üìä Toplam parametreler: {self.model.count_params():,}")
        
        return self.model
    
    def create_custom_cnn_model(self):
        """Geli≈ütirilmi≈ü √∂zel CNN modeli olu≈üturur."""
        print("üß† Geli≈ümi≈ü √∂zel CNN modeli olu≈üturuluyor...")
        
        self.model = Sequential([
            # ƒ∞lk Conv Block
            Conv2D(64, (3, 3), activation='relu', input_shape=(224, 224, 3)),
            BatchNormalization(),
            Conv2D(64, (3, 3), activation='relu'),
            MaxPooling2D(2, 2),
            Dropout(0.25),
            
            # ƒ∞kinci Conv Block
            Conv2D(128, (3, 3), activation='relu'),
            BatchNormalization(),
            Conv2D(128, (3, 3), activation='relu'),
            MaxPooling2D(2, 2),
            Dropout(0.25),
            
            # √ú√ß√ºnc√º Conv Block
            Conv2D(256, (3, 3), activation='relu'),
            BatchNormalization(),
            Conv2D(256, (3, 3), activation='relu'),
            MaxPooling2D(2, 2),
            Dropout(0.25),
            
            # D√∂rd√ºnc√º Conv Block
            Conv2D(512, (3, 3), activation='relu'),
            BatchNormalization(),
            Conv2D(512, (3, 3), activation='relu'),
            GlobalAveragePooling2D(),
            
            # Fully Connected Layers
            Dense(1024, activation='relu'),
            BatchNormalization(),
            Dropout(0.5),
            Dense(512, activation='relu'),
            BatchNormalization(),
            Dropout(0.3),
            Dense(256, activation='relu'),
            Dropout(0.2),
            Dense(3, activation='softmax')
        ])
        
        # Model derle
        self.model.compile(
            optimizer=Adam(learning_rate=0.001),
            loss='categorical_crossentropy',
            metrics=['accuracy', Precision(), Recall(), AUC()]
        )
        
        print("‚úÖ Geli≈ümi≈ü √∂zel CNN modeli olu≈üturuldu!")
        self.model.summary()
        
        return self.model
    
    def prepare_advanced_data(self):
        """Geli≈ümi≈ü veri √∂n i≈üleme ve augmentation."""
        print("\nüìä Geli≈ümi≈ü veri hazƒ±rlanƒ±yor...")
        
        # Agresif data augmentation - eƒüitim seti i√ßin
        train_datagen = ImageDataGenerator(
            rescale=1./255,
            rotation_range=40,
            width_shift_range=0.3,
            height_shift_range=0.3,
            shear_range=0.3,
            zoom_range=0.3,
            horizontal_flip=True,
            vertical_flip=True,
            brightness_range=[0.8, 1.2],
            channel_shift_range=0.2,
            fill_mode='nearest'
        )
        
        # Doƒürulama i√ßin sadece normalizasyon
        validation_datagen = ImageDataGenerator(rescale=1./255)
        
        # Veri y√ºkleme
        train_generator = train_datagen.flow_from_directory(
            'data/processed/train',
            target_size=self.img_size,
            batch_size=self.batch_size,
            class_mode='categorical',
            classes=self.class_names,
            shuffle=True
        )
        
        validation_generator = validation_datagen.flow_from_directory(
            'data/processed/validation',
            target_size=self.img_size,
            batch_size=self.batch_size,
            class_mode='categorical',
            classes=self.class_names,
            shuffle=False
        )
        
        print("‚úÖ Geli≈ümi≈ü veri hazƒ±rlandƒ±!")
        print(f"üìà Eƒüitim √∂rnekleri: {train_generator.samples}")
        print(f"üìä Doƒürulama √∂rnekleri: {validation_generator.samples}")
        
        return train_generator, validation_generator
    
    def calculate_class_weights(self, train_generator):
        """Dengesiz dataset i√ßin class weights hesaplar."""
        print("\n‚öñÔ∏è Class weights hesaplanƒ±yor...")
        
        # Sƒ±nƒ±f etiketlerini al
        y_train = train_generator.classes
        
        # Class weights hesapla
        class_weights = compute_class_weight(
            'balanced',
            classes=np.unique(y_train),
            y=y_train
        )
        
        class_weight_dict = dict(enumerate(class_weights))
        
        print(f"üìä Class weights: {class_weight_dict}")
        return class_weight_dict
    
    def cosine_annealing(self, epoch, lr_max=0.001, lr_min=0.0001, cycle_length=10):
        """Cosine annealing learning rate scheduler."""
        cycle = np.floor(1 + epoch / cycle_length)
        x = np.abs(epoch / cycle_length - cycle)
        lr = lr_min + (lr_max - lr_min) * 0.5 * (1 + np.cos(np.pi * x))
        return lr
    
    def train_advanced(self, epochs=100, use_transfer_learning=True):
        """Geli≈ümi≈ü eƒüitim s√ºreci."""
        print(f"\nüöÄ Geli≈ümi≈ü model eƒüitimi ba≈ülƒ±yor... ({epochs} epoch)")
        
        # Model olu≈ütur
        if use_transfer_learning:
            self.create_transfer_learning_model()
        else:
            self.create_custom_cnn_model()
        
        # Veri hazƒ±rla
        train_gen, val_gen = self.prepare_advanced_data()
        
        # Class weights hesapla
        class_weights = self.calculate_class_weights(train_gen)
        
        # Geli≈ümi≈ü callbacks
        callbacks = [
            EarlyStopping(
                monitor='val_accuracy',
                patience=15,
                restore_best_weights=True,
                verbose=1,
                min_delta=0.001
            ),
            ModelCheckpoint(
                'model/best_improved_model.h5',
                monitor='val_accuracy',
                save_best_only=True,
                verbose=1,
                save_weights_only=False
            ),
            ReduceLROnPlateau(
                monitor='val_loss',
                factor=0.3,
                patience=8,
                min_lr=0.00001,
                verbose=1,
                cooldown=3
            ),
            LearningRateScheduler(
                lambda epoch: self.cosine_annealing(epoch),
                verbose=1
            )
        ]
        
        # ƒ∞lk eƒüitim (frozen base)
        print("\nüîí 1. A≈üama: Frozen base ile eƒüitim...")
        history1 = self.model.fit(
            train_gen,
            steps_per_epoch=max(1, train_gen.samples // self.batch_size),
            epochs=min(30, epochs//2),
            validation_data=val_gen,
            validation_steps=max(1, val_gen.samples // self.batch_size),
            callbacks=callbacks,
            class_weight=class_weights,
            verbose=1
        )
        
        # Transfer learning varsa fine-tuning
        if use_transfer_learning:
            print("\nüîì 2. A≈üama: Fine-tuning...")
            
            # Base model'i unfreeze et
            self.model.layers[0].trainable = True
            
            # Daha d√º≈ü√ºk learning rate ile yeniden compile
            self.model.compile(
                optimizer=Adam(learning_rate=0.0001),
                loss='categorical_crossentropy',
                metrics=['accuracy', Precision(), Recall(), AUC()]
            )
            
            # Fine-tuning eƒüitimi
            history2 = self.model.fit(
                train_gen,
                steps_per_epoch=max(1, train_gen.samples // self.batch_size),
                epochs=epochs - min(30, epochs//2),
                validation_data=val_gen,
                validation_steps=max(1, val_gen.samples // self.batch_size),
                callbacks=callbacks,
                class_weight=class_weights,
                verbose=1,
                initial_epoch=len(history1.history['loss'])
            )
            
            # History'leri birle≈ütir
            self.history = self.combine_histories(history1, history2)
        else:
            self.history = history1
        
        print("‚úÖ Geli≈ümi≈ü model eƒüitimi tamamlandƒ±!")
        
        # Modeli kaydet
        self.save_improved_model()
        
        # Eƒüitim grafiklerini √ßiz
        self.plot_advanced_training_history()
        
        return self.history
    
    def combine_histories(self, hist1, hist2):
        """ƒ∞ki history'yi birle≈ütirir."""
        combined = {}
        for key in hist1.history.keys():
            combined[key] = hist1.history[key] + hist2.history[key]
        
        class CombinedHistory:
            def __init__(self, history_dict):
                self.history = history_dict
        
        return CombinedHistory(combined)
    
    def save_improved_model(self):
        """Geli≈ütirilmi≈ü modeli kaydeder."""
        print("\nüíæ Geli≈ümi≈ü model kaydediliyor...")
        
        # Model klas√∂r√ºn√º olu≈ütur
        Path("model").mkdir(exist_ok=True)
        
        # Ana modeli g√ºncelle
        self.model.save('model/skin_cancer_model.h5')
        
        # Backup olarak improved model
        self.model.save('model/improved_skin_cancer_model.h5')
        
        # Sƒ±nƒ±f bilgileri
        class_info = {
            'class_names': self.class_names,
            'class_descriptions': {
                'benign': 'ƒ∞yi huylu lezyon - Genellikle zararsƒ±z',
                'melanoma': 'Melanom - K√∂t√º huylu, acil tƒ±bbi m√ºdahale gerekli',
                'nevus': 'Nev√ºs (Ben) - Genellikle zararsƒ±z pigment lezyonu'
            },
            'model_info': {
                'architecture': 'Transfer Learning + EfficientNetB3',
                'input_size': self.img_size,
                'total_params': int(self.model.count_params())
            }
        }
        
        with open('model/class_info.json', 'w', encoding='utf-8') as f:
            json.dump(class_info, f, ensure_ascii=False, indent=2)
        
        print("‚úÖ Geli≈ümi≈ü model kaydedildi!")
    
    def plot_advanced_training_history(self):
        """Geli≈ümi≈ü eƒüitim grafiklerini √ßizer."""
        if self.history is None:
            print("‚ùå Eƒüitim ge√ßmi≈üi bulunamadƒ±!")
            return
        
        print("\nüìà Geli≈ümi≈ü eƒüitim grafikleri √ßiziliyor...")
        
        plt.switch_backend('Agg')
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        
        # Accuracy
        axes[0,0].plot(self.history.history['accuracy'], label='Eƒüitim Doƒüruluƒüu')
        axes[0,0].plot(self.history.history['val_accuracy'], label='Doƒürulama Doƒüruluƒüu')
        axes[0,0].set_title('Model Doƒüruluƒüu')
        axes[0,0].set_xlabel('Epoch')
        axes[0,0].set_ylabel('Doƒüruluk')
        axes[0,0].legend()
        axes[0,0].grid(True)
        
        # Loss
        axes[0,1].plot(self.history.history['loss'], label='Eƒüitim Kaybƒ±')
        axes[0,1].plot(self.history.history['val_loss'], label='Doƒürulama Kaybƒ±')
        axes[0,1].set_title('Model Kaybƒ±')
        axes[0,1].set_xlabel('Epoch')
        axes[0,1].set_ylabel('Kayƒ±p')
        axes[0,1].legend()
        axes[0,1].grid(True)
        
        # Precision
        axes[1,0].plot(self.history.history['precision'], label='Eƒüitim Precision')
        axes[1,0].plot(self.history.history['val_precision'], label='Doƒürulama Precision')
        axes[1,0].set_title('Model Precision')
        axes[1,0].set_xlabel('Epoch')
        axes[1,0].set_ylabel('Precision')
        axes[1,0].legend()
        axes[1,0].grid(True)
        
        # Recall
        axes[1,1].plot(self.history.history['recall'], label='Eƒüitim Recall')
        axes[1,1].plot(self.history.history['val_recall'], label='Doƒürulama Recall')
        axes[1,1].set_title('Model Recall')
        axes[1,1].set_xlabel('Epoch')
        axes[1,1].set_ylabel('Recall')
        axes[1,1].legend()
        axes[1,1].grid(True)
        
        plt.tight_layout()
        plt.savefig('model/improved_training_history.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        print("‚úÖ Geli≈ümi≈ü eƒüitim grafikleri kaydedildi!")
    
    def evaluate_improved_model(self):
        """Geli≈ümi≈ü modeli deƒüerlendirir."""
        print("\nüîç Geli≈ümi≈ü model test setinde deƒüerlendiriliyor...")
        
        test_datagen = ImageDataGenerator(rescale=1./255)
        test_generator = test_datagen.flow_from_directory(
            'data/processed/test',
            target_size=self.img_size,
            batch_size=self.batch_size,
            class_mode='categorical',
            classes=self.class_names,
            shuffle=False
        )
        
        # Deƒüerlendirme
        results = self.model.evaluate(test_generator, verbose=1)
        
        print(f"üìä Geli≈ümi≈ü Test Sonu√ßlarƒ±:")
        print(f"   - Test Kaybƒ±: {results[0]:.4f}")
        print(f"   - Test Doƒüruluƒüu: {results[1]:.4f} ({results[1]*100:.2f}%)")
        print(f"   - Test Precision: {results[2]:.4f}")
        print(f"   - Test Recall: {results[3]:.4f}")
        print(f"   - Test AUC: {results[4]:.4f}")
        
        return results

def main():
    """Geli≈ümi≈ü eƒüitim ana fonksiyonu."""
    print("üéØ SkinAI - Geli≈ümi≈ü Cilt Kanseri Sƒ±nƒ±flandƒ±rma Modeli")
    print("=" * 70)
    
    # Veri kontrol√º
    data_path = Path("data/processed/train")
    if not data_path.exists():
        print("‚ùå Eƒüitim veri seti bulunamadƒ±!")
        print("üëâ √ñnce veri setini hazƒ±rlayƒ±n: python utils/download_data.py")
        return
    
    # Geli≈ümi≈ü model olu≈ütur ve eƒüit
    improved_cnn = ImprovedSkinCancerCNN()
    
    # Transfer learning ile eƒüitim (daha iyi sonu√ßlar i√ßin)
    history = improved_cnn.train_advanced(
        epochs=80, 
        use_transfer_learning=True
    )
    
    # Test deƒüerlendirmesi
    improved_cnn.evaluate_improved_model()
    
    print("\nüéâ Geli≈ümi≈ü model eƒüitimi tamamlandƒ±!")
    print("üëâ Web uygulamasƒ±nƒ± ba≈ülatƒ±n: python app.py")

if __name__ == "__main__":
    main() 